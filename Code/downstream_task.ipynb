{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace/COSCI-GAN_Journal\n"
     ]
    }
   ],
   "source": [
    "\"\"\" validation/test set을 real 데이터로 사용 \"\"\"\n",
    "import os, joblib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from utils import set_seed\n",
    "\n",
    "path = '/workspace/COSCI-GAN_Journal'\n",
    "try:\n",
    "    os.chdir(path)\n",
    "    print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "except FileNotFoundError:\n",
    "    print(\"Directory {0} does not exist\".format(path))\n",
    "    \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_seed(42)\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 126개의 시계열 데이터를 사용하여 다음 스텝의 상승/하락 여부를 예측\n",
    "input_size = 5  # feature 개수\n",
    "output_size = 5\n",
    "hidden_size = 20\n",
    "num_layers = 2\n",
    "lr = 0.001\n",
    "dropout = 0.0\n",
    "num_repeats = 10  # 반복 횟수\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out)  # 모든 timestep에 대해 예측        \n",
    "        out = self.sigmoid(out)        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (4904, 127)\n",
      "5 (5000, 127)\n",
      "(4904, 127, 5) (5000, 127, 5)\n"
     ]
    }
   ],
   "source": [
    "# COSCI-GAN, TransGAN 데이터 로드\n",
    "real = joblib.load('./Output/real_list.pkl')\n",
    "fake = joblib.load('./Output/fake_list.pkl')\n",
    "    \n",
    "print(len(real), real[0].shape)\n",
    "print(len(fake), fake[0].shape)\n",
    "\n",
    "real_arr = np.transpose(np.array(real), (1, 2, 0))\n",
    "fake_arr = np.transpose(np.array(fake), (1, 2, 0))\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "real_arr = scaler.fit_transform(real_arr.reshape(-1, real_arr.shape[-1])).reshape(real_arr.shape)\n",
    "fake_arr = scaler.transform(fake_arr.reshape(-1, fake_arr.shape[-1])).reshape(fake_arr.shape)\n",
    "\n",
    "print(real_arr.shape, fake_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation for training and testing\n",
    "def prepare_data(data):\n",
    "    X = data[:, :-1, :]  # 마지막 timestep 제외\n",
    "    y = data[:, 1:, :]  # 첫번째 timestep 제외 (전체 시퀀스 예측)\n",
    "    return X, y\n",
    "\n",
    "# Weekly data preparation\n",
    "def prepare_weekly_data(data, interval=5):\n",
    "    num_samples, num_timesteps, num_features = data.shape\n",
    "    num_weeks = num_timesteps // interval\n",
    "    weekly_data = np.zeros((num_samples, num_weeks, num_features))\n",
    "    \n",
    "    for i in range(num_weeks):\n",
    "        weekly_data[:, i, :] = data[:, i*interval:(i+1)*interval, :].mean(axis=1)\n",
    "    \n",
    "    return weekly_data\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_train_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient Clipping\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        epoch_train_loss /= len(train_loader)\n",
    "        #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_train_loss:.4f}\")\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "            outputs = model(x_test)\n",
    "            all_predictions.append(outputs.cpu())\n",
    "            all_targets.append(y_test.cpu())\n",
    "\n",
    "    all_predictions = torch.cat(all_predictions).view(-1, all_predictions[0].shape[-1])\n",
    "    all_targets = torch.cat(all_targets).view(-1, all_targets[0].shape[-1])\n",
    "\n",
    "    mse = mean_squared_error(all_targets, all_predictions)\n",
    "    mae = mean_absolute_error(all_targets, all_predictions)\n",
    "    r2 = r2_score(all_targets, all_predictions)\n",
    "\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"R^2 Score: {r2:.4f}\")\n",
    "    \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 1/10\n",
      "Mean Squared Error (MSE): 0.0027\n",
      "Mean Absolute Error (MAE): 0.0340\n",
      "R^2 Score: -0.0589\n",
      "Repeat 2/10\n",
      "Mean Squared Error (MSE): 0.0027\n",
      "Mean Absolute Error (MAE): 0.0340\n",
      "R^2 Score: -0.0617\n",
      "Repeat 3/10\n",
      "Mean Squared Error (MSE): 0.0027\n",
      "Mean Absolute Error (MAE): 0.0338\n",
      "R^2 Score: -0.0579\n",
      "Repeat 4/10\n",
      "Mean Squared Error (MSE): 0.0027\n",
      "Mean Absolute Error (MAE): 0.0340\n",
      "R^2 Score: -0.0638\n",
      "Repeat 5/10\n",
      "Mean Squared Error (MSE): 0.0027\n",
      "Mean Absolute Error (MAE): 0.0342\n",
      "R^2 Score: -0.0746\n",
      "Repeat 6/10\n",
      "Mean Squared Error (MSE): 0.0027\n",
      "Mean Absolute Error (MAE): 0.0341\n",
      "R^2 Score: -0.0617\n",
      "Repeat 7/10\n",
      "Mean Squared Error (MSE): 0.0027\n",
      "Mean Absolute Error (MAE): 0.0340\n",
      "R^2 Score: -0.0655\n",
      "Repeat 8/10\n",
      "Mean Squared Error (MSE): 0.0027\n",
      "Mean Absolute Error (MAE): 0.0339\n",
      "R^2 Score: -0.0557\n",
      "Repeat 9/10\n",
      "Mean Squared Error (MSE): 0.0027\n",
      "Mean Absolute Error (MAE): 0.0339\n",
      "R^2 Score: -0.0582\n",
      "Repeat 10/10\n",
      "Mean Squared Error (MSE): 0.0027\n",
      "Mean Absolute Error (MAE): 0.0339\n",
      "R^2 Score: -0.0638\n",
      "MAE Mean: 0.0340, MAE Std: 0.0001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare data for synthetic dataset\n",
    "X_fake, y_fake = prepare_data(fake_arr)\n",
    "X_fake = torch.tensor(X_fake, dtype=torch.float32)\n",
    "y_fake = torch.tensor(y_fake, dtype=torch.float32)\n",
    "\n",
    "train_dataset_fake = TensorDataset(X_fake, y_fake)\n",
    "train_loader_fake = DataLoader(train_dataset_fake, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Prepare data for original dataset\n",
    "X_ori, y_ori = prepare_data(real_arr)\n",
    "X_ori = torch.tensor(X_ori, dtype=torch.float32)\n",
    "y_ori = torch.tensor(y_ori, dtype=torch.float32)\n",
    "\n",
    "test_dataset_ori = TensorDataset(X_ori, y_ori)\n",
    "test_loader_ori = DataLoader(test_dataset_ori, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Main loop for multiple repetitions\n",
    "mae_scores = []\n",
    "\n",
    "for i in range(num_repeats):\n",
    "    print(f\"Repeat {i+1}/{num_repeats}\")\n",
    "    \n",
    "    # Initialize and train model\n",
    "    model = Regressor(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.L1Loss()\n",
    "    \n",
    "    train_model(model, train_loader_fake, criterion, optimizer, num_epochs, device)\n",
    "    \n",
    "    # Evaluate model\n",
    "    mae = evaluate_model(model, test_loader_ori, device)\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "# Calculate mean and standard deviation of MAE\n",
    "print()\n",
    "mae_mean = np.mean(mae_scores)\n",
    "mae_std = np.std(mae_scores)\n",
    "print(f\"MAE Mean: {mae_mean:.4f}, MAE Std: {mae_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 1/10\n",
      "Mean Squared Error (MSE): 0.0005\n",
      "Mean Absolute Error (MAE): 0.0147\n",
      "R^2 Score: -0.0214\n",
      "Repeat 2/10\n",
      "Mean Squared Error (MSE): 0.0005\n",
      "Mean Absolute Error (MAE): 0.0148\n",
      "R^2 Score: -0.0341\n",
      "Repeat 3/10\n",
      "Mean Squared Error (MSE): 0.0005\n",
      "Mean Absolute Error (MAE): 0.0148\n",
      "R^2 Score: -0.0208\n",
      "Repeat 4/10\n",
      "Mean Squared Error (MSE): 0.0005\n",
      "Mean Absolute Error (MAE): 0.0147\n",
      "R^2 Score: -0.0223\n",
      "Repeat 5/10\n",
      "Mean Squared Error (MSE): 0.0005\n",
      "Mean Absolute Error (MAE): 0.0147\n",
      "R^2 Score: -0.0246\n",
      "Repeat 6/10\n",
      "Mean Squared Error (MSE): 0.0005\n",
      "Mean Absolute Error (MAE): 0.0148\n",
      "R^2 Score: -0.0207\n",
      "Repeat 7/10\n",
      "Mean Squared Error (MSE): 0.0005\n",
      "Mean Absolute Error (MAE): 0.0148\n",
      "R^2 Score: -0.0242\n",
      "Repeat 8/10\n",
      "Mean Squared Error (MSE): 0.0005\n",
      "Mean Absolute Error (MAE): 0.0147\n",
      "R^2 Score: -0.0156\n",
      "Repeat 9/10\n",
      "Mean Squared Error (MSE): 0.0005\n",
      "Mean Absolute Error (MAE): 0.0148\n",
      "R^2 Score: -0.0179\n",
      "Repeat 10/10\n",
      "Mean Squared Error (MSE): 0.0005\n",
      "Mean Absolute Error (MAE): 0.0148\n",
      "R^2 Score: -0.0271\n",
      "MAE Mean: 0.0148, MAE Std: 0.0000\n"
     ]
    }
   ],
   "source": [
    "real_weekly = prepare_weekly_data(real_arr[:, 2:, :])\n",
    "fake_weekly = prepare_weekly_data(fake_arr[:, 2:, :])\n",
    "\n",
    "# Prepare data for synthetic dataset\n",
    "X_fake, y_fake = prepare_data(fake_weekly)\n",
    "X_fake = torch.tensor(X_fake, dtype=torch.float32)\n",
    "y_fake = torch.tensor(y_fake, dtype=torch.float32)\n",
    "\n",
    "train_dataset_fake = TensorDataset(X_fake, y_fake)\n",
    "train_loader_fake = DataLoader(train_dataset_fake, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Prepare data for original dataset\n",
    "X_ori, y_ori = prepare_data(real_weekly)\n",
    "X_ori = torch.tensor(X_ori, dtype=torch.float32)\n",
    "y_ori = torch.tensor(y_ori, dtype=torch.float32)\n",
    "\n",
    "test_dataset_ori = TensorDataset(X_ori, y_ori)\n",
    "test_loader_ori = DataLoader(test_dataset_ori, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Main loop for multiple repetitions\n",
    "mae_scores = []\n",
    "\n",
    "for i in range(num_repeats):\n",
    "    print(f\"Repeat {i+1}/{num_repeats}\")\n",
    "    \n",
    "    # Initialize and train model\n",
    "    model = Regressor(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.L1Loss()\n",
    "    \n",
    "    train_model(model, train_loader_fake, criterion, optimizer, num_epochs, device)\n",
    "    \n",
    "    # Evaluate model\n",
    "    mae = evaluate_model(model, test_loader_ori, device)\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "# Calculate mean and standard deviation of MAE\n",
    "print()\n",
    "mae_mean = np.mean(mae_scores)\n",
    "mae_std = np.std(mae_scores)\n",
    "print(f\"MAE Mean: {mae_mean:.4f}, MAE Std: {mae_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 예측값과 실제 값을 플롯\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# plt.plot(targets[:100, 0].cpu(), label='True Values', marker='o', linestyle='dashed')\n",
    "# plt.plot(predictions[:100, 0].cpu(), label='Predicted Values', marker='x')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('True vs Predicted Values')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
